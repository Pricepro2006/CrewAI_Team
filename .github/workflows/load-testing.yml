name: Load Testing

on:
  workflow_dispatch:
    inputs:
      duration:
        description: 'Test duration (e.g., 30s, 2m, 5m)'
        required: false
        default: '30s'
      users:
        description: 'Number of virtual users'
        required: false
        default: '10'
      
  schedule:
    # Run load tests every Sunday at 3 AM UTC
    - cron: '0 3 * * 0'

jobs:
  load-test:
    name: Load Testing with k6
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: pnpm/action-setup@v4
        with:
          version: 9
          
      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
          
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
        
      - name: Install and setup Ollama for load testing
        run: |
          # Install Ollama
          curl -fsSL https://ollama.com/install.sh | sh
          
          # Start Ollama server in background
          ollama serve &
          
          # Wait for Ollama to be ready
          echo "Waiting for Ollama to start..."
          for i in {1..30}; do
            if curl -s -f http://localhost:11434/api/version > /dev/null 2>&1; then
              echo "Ollama is ready for load testing!"
              break
            fi
            echo "Attempt $i: Ollama not ready yet, waiting..."
            sleep 2
          done
          
          # Pull required models for load testing
          ollama pull qwen2.5:0.5b
          ollama pull nomic-embed-text
          
      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
          
      - name: Create k6 load test script
        run: |
          mkdir -p load-tests
          cat > load-tests/api-load-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate } from 'k6/metrics';
          
          export let errorRate = new Rate('errors');
          
          export let options = {
            stages: [
              { duration: '2m', target: __ENV.VUS || 10 }, // Ramp up
              { duration: __ENV.DURATION || '30s', target: __ENV.VUS || 10 }, // Stay at target
              { duration: '2m', target: 0 }, // Ramp down
            ],
            thresholds: {
              http_req_duration: ['p(95)<1000'], // 95% of requests must complete below 1s
              errors: ['rate<0.1'], // Error rate must be below 10%
            },
          };
          
          export default function() {
            // Test health endpoint
            let healthResponse = http.get('http://localhost:3000/health');
            check(healthResponse, {
              'health check status is 200': (r) => r.status === 200,
              'health check response time < 500ms': (r) => r.timings.duration < 500,
            }) || errorRate.add(1);
            
            // Test tRPC endpoints
            let trpcResponse = http.get('http://localhost:3000/api/trpc/health.check');
            check(trpcResponse, {
              'tRPC health status is 200': (r) => r.status === 200,
              'tRPC response time < 1000ms': (r) => r.timings.duration < 1000,
            }) || errorRate.add(1);
            
            // Test API with different load patterns
            if (Math.random() < 0.3) {
              // 30% of requests: Test chat endpoint with mock data
              let chatPayload = JSON.stringify({
                message: 'Hello, this is a load test message',
                sessionId: 'load-test-session'
              });
              
              let chatResponse = http.post('http://localhost:3000/api/trpc/chat.sendMessage', chatPayload, {
                headers: {
                  'Content-Type': 'application/json',
                },
              });
              
              check(chatResponse, {
                'chat endpoint responds': (r) => r.status < 500,
                'chat response time acceptable': (r) => r.timings.duration < 5000,
              }) || errorRate.add(1);
            }
            
            sleep(1);
          }
          EOF
          
      - name: Start application for load testing
        run: |
          # Start the server in background
          timeout 300s pnpm dev:server &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          
          # Wait for server to start
          echo "Waiting for server to start..."
          for i in {1..30}; do
            if curl -s -f http://localhost:3000/health > /dev/null 2>&1; then
              echo "Server is ready for load testing!"
              break
            fi
            echo "Waiting for server... ($i/30)"
            sleep 2
          done
          
      - name: Run k6 load test
        run: |
          echo "Running k6 load test..."
          k6 run load-tests/api-load-test.js \
            --env VUS=${{ github.event.inputs.users || '10' }} \
            --env DURATION=${{ github.event.inputs.duration || '30s' }} \
            --out json=load-test-results.json
        env:
          OLLAMA_URL: http://localhost:11434
          
      - name: Process load test results
        run: |
          echo "Processing load test results..."
          
          # Extract key metrics from k6 results
          node -e "
            const fs = require('fs');
            const results = fs.readFileSync('load-test-results.json', 'utf8');
            const lines = results.trim().split('\n');
            const metrics = {};
            
            lines.forEach(line => {
              try {
                const data = JSON.parse(line);
                if (data.type === 'Point' && data.data && data.data.value !== undefined) {
                  const metricName = data.metric;
                  if (!metrics[metricName]) {
                    metrics[metricName] = [];
                  }
                  metrics[metricName].push(data.data.value);
                }
              } catch (e) {
                // Skip invalid JSON lines
              }
            });
            
            // Calculate summary statistics
            const summary = {};
            Object.keys(metrics).forEach(metric => {
              const values = metrics[metric];
              if (values.length > 0) {
                const sorted = values.sort((a, b) => a - b);
                summary[metric] = {
                  count: values.length,
                  min: Math.min(...values),
                  max: Math.max(...values),
                  avg: values.reduce((a, b) => a + b, 0) / values.length,
                  p95: sorted[Math.floor(sorted.length * 0.95)],
                  p99: sorted[Math.floor(sorted.length * 0.99)]
                };
              }
            });
            
            // Create summary report
            const report = {
              timestamp: new Date().toISOString(),
              test_config: {
                duration: process.env.DURATION || '30s',
                users: process.env.VUS || '10'
              },
              metrics: summary
            };
            
            fs.writeFileSync('load-test-summary.json', JSON.stringify(report, null, 2));
            
            // Create human-readable report
            let humanReport = '# Load Test Results\n\n';
            humanReport += '## Test Configuration\n';
            humanReport += '- Duration: ' + (process.env.DURATION || '30s') + '\n';
            humanReport += '- Virtual Users: ' + (process.env.VUS || '10') + '\n';
            humanReport += '- Timestamp: ' + new Date().toISOString() + '\n\n';
            
            humanReport += '## Key Metrics\n';
            if (summary.http_req_duration) {
              humanReport += '### HTTP Request Duration\n';
              humanReport += '- Average: ' + summary.http_req_duration.avg.toFixed(2) + 'ms\n';
              humanReport += '- 95th Percentile: ' + summary.http_req_duration.p95.toFixed(2) + 'ms\n';
              humanReport += '- 99th Percentile: ' + summary.http_req_duration.p99.toFixed(2) + 'ms\n';
              humanReport += '- Max: ' + summary.http_req_duration.max.toFixed(2) + 'ms\n\n';
            }
            
            if (summary.errors) {
              const errorRate = (summary.errors.avg * 100).toFixed(2);
              humanReport += '### Error Rate\n';
              humanReport += '- Error Rate: ' + errorRate + '%\n\n';
            }
            
            fs.writeFileSync('load-test-report.md', humanReport);
            
            console.log('Load test summary generated successfully!');
          "
          
      - name: Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            load-test-results.json
            load-test-summary.json
            load-test-report.md
          retention-days: 30
          
      - name: Comment results on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              const report = fs.readFileSync('load-test-report.md', 'utf8');
              
              const comment = `## ðŸš€ Load Test Results
              
              ${report}
              
              ### Next Steps
              - Review the detailed metrics in the artifacts
              - Check for any performance regressions
              - Optimize if response times exceed thresholds
              
              ðŸ“Š Full results available in workflow artifacts.`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('No load test report found or error reading file:', error.message);
            }
            
      - name: Cleanup
        if: always()
        run: |
          # Kill server if still running
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || true
          fi
          
          # Kill any remaining processes
          pkill -f "pnpm dev:server" || true
          pkill -f "ollama serve" || true
          
          echo "Cleanup completed!"