# Ollama Configuration for Production
# These settings help prevent timeout issues with large models

# Request timeout (10 minutes for complex operations)
OLLAMA_REQUEST_TIMEOUT=600s

# Keep models loaded in memory for 30 minutes
OLLAMA_KEEP_ALIVE=30m

# Maximum number of models to keep loaded
OLLAMA_MAX_LOADED_MODELS=3

# Maximum request queue size
OLLAMA_MAX_QUEUE=512

# Number of parallel requests
OLLAMA_NUM_PARALLEL=4

# GPU layers (adjust based on your GPU memory)
OLLAMA_GPU_LAYERS=35