#!/usr/bin/env tsx

import { SafeLlamaCppProvider } from "../src/core/llm/SafeLlamaCppProvider.js";
import * as path from "path";
import * as fs from "fs";

async function testLlamaIntegration() {
  console.log("üß™ Testing llama.cpp integration...\n");
  
  const modelPath = "./models/Llama-3.2-3B-Instruct-Q4_K_M.gguf";
  
  // Check if model exists
  if (!fs.existsSync(modelPath)) {
    console.error("‚ùå Model file not found:", modelPath);
    process.exit(1);
  }
  
  console.log("‚úÖ Model file found:", modelPath);
  
  try {
    // Create provider instance
    const provider = new SafeLlamaCppProvider({
      modelPath: modelPath,
      contextSize: 2048,
      threads: 4,
      temperature: 0.7,
      maxTokens: 50,
      processTimeout: 30000,
    });
    
    console.log("üì¶ Initializing llama.cpp provider...");
    
    // Initialize (verify model loads)
    await provider.initialize();
    console.log("‚úÖ Provider initialized successfully");
    
    // Test generation
    console.log("\nü§ñ Testing text generation...");
    console.log("Prompt: 'What is artificial intelligence?'");
    
    const response = await provider.generate(
      "What is artificial intelligence?",
      {
        maxTokens: 50,
        temperature: 0.7
      }
    );
    
    console.log("\nüìù Response:");
    console.log("-------------");
    console.log(response.response);
    console.log("-------------");
    
    console.log("\nüìä Metrics:");
    console.log(`- Tokens generated: ${response.tokensGenerated}`);
    console.log(`- Tokens per second: ${response.tokensPerSecond?.toFixed(2)}`);
    console.log(`- Total duration: ${response.totalDuration}ms`);
    
    // Test with system prompt
    console.log("\nü§ñ Testing with system prompt...");
    const response2 = await provider.generate(
      "List 3 benefits",
      {
        maxTokens: 50,
        temperature: 0.7,
        systemPrompt: "You are a helpful assistant. Be concise."
      }
    );
    
    console.log("\nüìù Response with system prompt:");
    console.log("-------------");
    console.log(response2.response);
    console.log("-------------");
    
    // Cleanup
    await provider.cleanup();
    console.log("\n‚úÖ Cleanup completed");
    
    console.log("\nüéâ All tests passed!");
    
  } catch (error) {
    console.error("\n‚ùå Test failed:", error);
    process.exit(1);
  }
}

// Run the test
testLlamaIntegration().catch(console.error);